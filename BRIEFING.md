# ğŸ“‹ BRIEFING - Proyecto Individual Bootcamp IA

## ğŸ¯ 1. Problema Identificado

### **Contexto**
Las plataformas de streaming musical (Spotify, Deezer, Apple Music) ofrecen millones de canciones, pero encontrar mÃºsica que encaje con un **estado emocional especÃ­fico** requiere:
- Navegar por mÃºltiples playlists genÃ©ricas
- Conocer nombres de gÃ©neros especÃ­ficos
- Perder tiempo en bÃºsquedas iterativas

### **Pain Points**
- âŒ "Quiero mÃºsica para concentrarme estudiando de noche" â†’ Â¿quÃ© playlist busco?
- âŒ "Me siento triste despuÃ©s de una ruptura" â†’ Â¿lo-fi? Â¿indie? Â¿baladas?
- âŒ Barreras idiomÃ¡ticas: usuarios no tÃ©cnicos no conocen tÃ©rminos como "downtempo" o "chillhop"

### **PÃºblico Objetivo**
- Personas que buscan mÃºsica por **contexto emocional**, no por gÃ©nero
- Usuarios que quieren descubrir mÃºsica nueva sin esfuerzo cognitivo
- Edades 18-45 aÃ±os, familiarizados con streaming pero frustrados con la bÃºsqueda

---

## ğŸ’¡ 2. Propuesta de SoluciÃ³n

### **Concepto**
**MoodTune**: Un asistente de descubrimiento musical que traduce descripciones naturales en lenguaje humano ("estudiando con lluvia, necesito foco") a recomendaciones musicales precisas.

### **Â¿Por quÃ© IA?**
- **LLM (GPT-4o-mini)** interpreta el **contexto semÃ¡ntico** del mood:
  - Extrae emociones ("triste", "energÃ©tico", "romÃ¡ntico")
  - Infiere nivel de energÃ­a (low/medium/high)
  - Traduce a gÃ©neros musicales relevantes
  - Genera queries optimizadas para APIs de mÃºsica

- **Sin IA**: Solo podrÃ­amos hacer bÃºsqueda literal (keyword matching), perdiendo contexto emocional complejo.

### **Valor Ãºnico**
- âœ… Interfaz en **lenguaje natural** (vs menÃºs y filtros complejos)
- âœ… **BilingÃ¼e** (espaÃ±ol e inglÃ©s) con detecciÃ³n automÃ¡tica
- âœ… **Previews instantÃ¡neas** de 30 segundos (sin login)
- âœ… Resultados **explicados** (metadata con mood interpretado)

---

## ğŸ—ï¸ 3. MVP Definido

### **Alcance MÃ­nimo (In-Scope)**
- [x] Input de texto libre (10-500 caracteres)
- [x] AnÃ¡lisis de mood con LLM (OpenAI GPT-4o-mini)
- [x] BÃºsqueda en Deezer Public API (sin autenticaciÃ³n)
- [x] Previews de audio (30s snippets)
- [x] Frontend responsive con Next.js + TypeScript
- [x] Backend API con FastAPI
- [x] Soporte bilingÃ¼e (ES/EN)
- [x] Rate limiting bÃ¡sico (10 req/min)

### **Fuera de Scope (Fase 2 potencial)**
- [ ] AutenticaciÃ³n de usuarios
- [ ] CreaciÃ³n de playlists persistentes
- [ ] Historial de bÃºsquedas
- [ ] Modelo ML propio (en vez de OpenAI)
- [ ] IntegraciÃ³n con Spotify

---

## ğŸ› ï¸ 4. Arquitectura TÃ©cnica

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Usuario   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Query: "triste y melancÃ³lico"
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FRONTEND (Next.js + TS)        â”‚
â”‚  - ValidaciÃ³n input (10-500)    â”‚
â”‚  - UI states (idle/loading/OK)  â”‚
â”‚  - Audio preview player         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ POST /api/discover
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BACKEND (FastAPI + Python)     â”‚
â”‚  - Rate limiting (10/min/IP)    â”‚
â”‚  - CORS middleware              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI   â”‚    â”‚ Deezer API   â”‚
â”‚ GPT-4o   â”‚    â”‚ (Search)     â”‚
â”‚ -mini    â”‚    â”‚              â”‚
â”‚          â”‚    â”‚              â”‚
â”‚ Analiza  â”‚    â”‚ Devuelve     â”‚
â”‚ mood     â”‚    â”‚ tracks       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Flujo de Datos**
1. Usuario escribe: "estudiando tarde con lluvia, necesito foco"
2. Frontend valida y envÃ­a a `/api/discover` (con idioma detectado)
3. Backend llama a **LLM Service** â†’ OpenAI analiza y devuelve:
   ```json
   {
     "mood_tags": ["focused", "calm", "studious"],
     "energy": "low",
     "genres": ["lo-fi", "ambient", "instrumental"],
     "search_query": "lo-fi study calm focus"
   }
   ```
4. Backend llama a **Deezer Service** con `search_query`
5. Deezer devuelve ~25 tracks con previews
6. Backend formatea y devuelve JSON al frontend
7. Frontend muestra cards con audio players

---

## ğŸ“š 5. Stack TecnolÃ³gico

| Capa | TecnologÃ­a | JustificaciÃ³n |
|------|-----------|---------------|
| **Frontend** | Next.js 14 (App Router) | SSR/SSG, React optimizado, TypeScript nativo |
| **UI Components** | React 19 + CSS Modules | Componentes reutilizables, estilos scoped |
| **Backend** | FastAPI (Python 3.11+) | Async, auto-docs, validaciÃ³n con Pydantic |
| **LLM** | OpenAI GPT-4o-mini | Costo-eficiente, JSON mode nativo, 128K context |
| **Music API** | Deezer Public API | Gratis, sin OAuth para bÃºsqueda/previews |
| **HTTP Client (backend)** | httpx | Async requests necesarios para FastAPI |
| **Rate Limiting** | slowapi | Compatible con FastAPI, basado en IP |
| **Deployment** | Vercel (FE) + Render (BE) | Free tiers, CI/CD integrado |

---

## ğŸ’¾ 6. Datos Utilizados

### **Fuente Principal**
- **Deezer Public API** (https://api.deezer.com)
  - CatÃ¡logo: ~90M tracks
  - GÃ©neros: Pop, Rock, Hip-Hop, Electronic, Classical, Jazz, etc.
  - Previews: MP3 de 30 segundos para cada track

### **Dataset Interno (CachÃ©)**
- **mood_cache.json** (backend/datasets/)
  - Almacena pares `(user_query, llm_analysis)` para acelerar respuestas repetidas
  - Inicialmente vacÃ­o, se va poblando con uso real
  - Ventaja: Reduce costos de llamadas a OpenAI (cache hits ~200ms vs 2-3s)

### **Sin datos de entrenamiento**
- No se entrena un modelo ML propio (fuera de scope del MVP)
- Se usa transfer learning con GPT-4o-mini pre-entrenado

---

## ğŸ“… 7. Plan de Desarrollo (Estimado)

| Fase | DuraciÃ³n | Tareas |
|------|----------|--------|
| **Setup inicial** | 1 dÃ­a | Crear repos, configurar FastAPI + Next.js, estructura de carpetas |
| **Backend core** | 2 dÃ­as | LLM service, Deezer service, endpoint `/api/discover`, validaciÃ³n |
| **Frontend core** | 2 dÃ­as | Form, TrackCard, audio preview, estados de carga |
| **Features UX** | 1.5 dÃ­as | BilingÃ¼e, tema oscuro/claro, ejemplos clickeables |
| **Seguridad** | 0.5 dÃ­as | Rate limiting, CORS, `.env.example`, SECURITY.md |
| **Testing local** | 1 dÃ­a | Tests manuales, scripts de prueba (test_llm_service.py) |
| **DocumentaciÃ³n** | 1 dÃ­a | README, PROJECT_STATUS, BRIEFING, ARQUITECTURA |
| **Deployment** | 1 dÃ­a | Render + Vercel setup, variables de entorno producciÃ³n |
| **Video demo** | 0.5 dÃ­as | Grabar, editar, subir demo de 3 minutos |

**Total estimado**: ~10 dÃ­as (asumiendo dedicaciÃ³n full-time)

---

## âœ… 8. Criterios de Ã‰xito

### **TÃ©cnicos**
- [x] Backend responde en <3 segundos (promedio)
- [x] Frontend sin errores de TypeScript
- [x] Tests manuales pasando (espaÃ±ol e inglÃ©s)
- [x] CORS configurado correctamente
- [x] Rate limiting funcionando (protecciÃ³n contra abuso)

### **De Negocio**
- [ ] Demo funcional mostrable en presentaciÃ³n de 5 min
- [ ] CÃ³digo en GitHub con commits limpios
- [ ] README profesional (puede incluirse en portfolio)

### **De Aprendizaje (Bootcamp)**
- [x] IntegraciÃ³n real de LLM en un producto usable
- [x] Arquitectura cliente-servidor bien diseÃ±ada
- [x] Buenas prÃ¡cticas de seguridad y documentaciÃ³n
- [x] Proyecto que demuestra habilidades full-stack + IA

---

## ğŸš€ 9. PrÃ³ximos Pasos Inmediatos

1. âœ… Implementar MVP (COMPLETADO)
2. âš ï¸ Crear video demo (PENDIENTE - CRÃTICO)
3. âš ï¸ Finalizar documentaciÃ³n (ARQUITECTURA.md faltante)
4. âš ï¸ Subir a GitHub y verificar que .env no estÃ© incluido
5. âš ï¸ Deploy a Vercel + Render (opcional pero recomendado)
6. âœ… Preparar presentaciÃ³n de 5 minutos

---

**Autor**: Umit Gungor  
**Proyecto**: MoodTune - AI-Powered Music Discovery  
**Bootcamp**: Proyecto Individual IA  
**Fecha**: Febrero 2026
