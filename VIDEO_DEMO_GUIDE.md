# ðŸŽ¬ GUÃA DE GRABACIÃ“N - Video Demo MoodTune

## ðŸŽ¯ Objetivo
Grabar un video de **2-3 minutos** demostrando MoodTune funcionalmente para cumplir con requisitos del Bootcamp.

---

## ðŸ“‹ Checklist Antes de Grabar

### **Setup TÃ©cnico**
- [ ] Backend corriendo: `cd backend && python main.py` (puerto 8000)
- [ ] Frontend corriendo: `cd frontend && npm run dev` (puerto 3000)
- [ ] Navegador abierto en `http://localhost:3000`
- [ ] Audio del sistema funcionando (para previews de canciones)
- [ ] Cerrar tabs innecesarias (solo MoodTune visible)

### **Setup de GrabaciÃ³n**
- [ ] Herramienta de grabaciÃ³n lista:
  - **Mac**: QuickTime Player (gratis)
  - **Windows**: OBS Studio (gratis) o Xbox Game Bar
  - **Multiplataforma**: Loom (gratis, recomendado)
- [ ] MicrÃ³fono testeado (audio claro)
- [ ] Ventana del navegador en **tamaÃ±o medio** (no fullscreen para mejor visibilidad)
- [ ] Preparar script mental (ver abajo)

---

## ðŸŽ¥ Estructura del Video (2:30 min)

### **INTRO (0:00 - 0:20) - 20 segundos**
```
[Pantalla: MoodTune homepage]

ðŸŽ¤ NarraciÃ³n:
"Hola, mi nombre es Umit y este es MoodTune, mi proyecto final del 
Bootcamp de IA. Es un asistente de descubrimiento musical que traduce 
descripciones emocionales en lenguaje natural a recomendaciones 
musicales personalizadas usando Inteligencia Artificial."

[Mostrar brevemente la interfaz sin hacer nada]
```

---

### **DEMO 1: Query en EspaÃ±ol (0:20 - 1:00) - 40 segundos**
```
[Escribir en el textarea mientras hablas]

ðŸŽ¤ NarraciÃ³n:
"Voy a demostrar cÃ³mo funciona. Imagina que me siento triste despuÃ©s 
de una ruptura y quiero mÃºsica apropiada."

[Escribir]: "triste y melancÃ³lico despuÃ©s de una ruptura"

"Hago click en Descubrir MÃºsica..."

[Click en botÃ³n]
[Esperar loading state - mostrar spinner]

"El sistema estÃ¡ usando OpenAI GPT-4o-mini para analizar el contexto 
emocional de mi descripciÃ³n..."

[Resultados aparecen]

"Â¡Y aquÃ­ estÃ¡n las recomendaciones! El AI interpretÃ³ mi mood como 
'Triste y MelancÃ³lico' con energÃ­a baja, y sugiriÃ³ gÃ©neros como 
balada, indie y mÃºsica acÃºstica."

[Scroll por las canciones brevemente]

"Puedo escuchar previews de 30 segundos directamente en la app..."

[Click en play de UNA canciÃ³n - dejar sonar 5 segundos]
[Pausar la canciÃ³n]
```

---

### **DEMO 2: Query en InglÃ©s + Features (1:00 - 1:50) - 50 segundos**
```
[Click en "Nueva BÃºsqueda" en la parte superior]

ðŸŽ¤ NarraciÃ³n:
"Ahora pruebo en inglÃ©s. Quiero mÃºsica para entrenar en el gimnasio."

[Escribir]: "working out at the gym, need energy"

[Click en Descubrir MÃºsica]
[Esperar resultados]

"Perfecto, ahora el AI detectÃ³ un mood energÃ©tico, sugiriendo gÃ©neros 
como EDM, Hip-Hop y ElectrÃ³nica."

[Mostrar las canciones brevemente]

"La aplicaciÃ³n es completamente bilingÃ¼e..."

[Click en icono de idioma en el header - cambiar a espaÃ±ol]
[Mostrar cÃ³mo la interfaz cambia a espaÃ±ol]

"...y tambiÃ©n tiene modo oscuro y claro."

[Click en icono de sol/luna - toggle theme]
[Mostrar el cambio visual]

[Volver a modo oscuro para mejor contraste]
```

---

### **TECNOLOGÃA (1:50 - 2:20) - 30 segundos**
```
[OpciÃ³n A: Mostrar cÃ³digo brevemente]
[Abrir VSCode con llm_service.py visible]

ðŸŽ¤ NarraciÃ³n:
"Por detrÃ¡s, la arquitectura usa un backend en FastAPI con Python que 
se comunica con la API de OpenAI. El modelo GPT-4o-mini analiza el 
lenguaje natural del usuario y extrae mood tags, nivel de energÃ­a y 
gÃ©neros musicales en formato JSON estructurado."

[Mostrar el cÃ³digo de analyze_mood por 5 segundos]

"Luego, esos datos se envÃ­an a la API de Deezer para buscar canciones 
reales, y el frontend en Next.js con TypeScript renderiza los resultados 
de forma interactiva."

[Volver al navegador con los resultados visible]

---

[OpciÃ³n B: Mostrar diagrama]
[Si tienes ARQUITECTURA.md abierto, mostrar el diagrama ASCII]

ðŸŽ¤ NarraciÃ³n:
"La arquitectura es sencilla pero efectiva: el usuario interactÃºa con 
un frontend en Next.js, que envÃ­a queries a un backend FastAPI. Este 
llama a OpenAI para anÃ¡lisis de mood y a Deezer para obtener mÃºsica 
real con previews de 30 segundos."
```

---

### **CIERRE (2:20 - 2:30) - 10 segundos**
```
[Pantalla: Homepage de MoodTune o resultados]

ðŸŽ¤ NarraciÃ³n:
"Todo el cÃ³digo estÃ¡ disponible en GitHub con documentaciÃ³n completa. 
Gracias por ver la demo de MoodTune."

[Fade out o corte]
```

---

## ðŸŽ¬ Tips de GrabaciÃ³n

### **Audio**
- âœ… Graba en un lugar **silencioso** (sin ruido de fondo)
- âœ… Habla **claro y a velocidad normal** (no apresures)
- âœ… SonrÃ­e al hablar (se nota en la voz, mÃ¡s energÃ­a)
- âš ï¸ Evita muletillas ("ehhh", "umm")

### **Video**
- âœ… **ResoluciÃ³n mÃ­nima**: 1080p (1920x1080)
- âœ… **Frame rate**: 30 FPS o superior
- âœ… No grabes en fullscreen (ventana de navegador mediana se ve mejor)
- âœ… Cursor visible y movimientos lentos (no saltes por la pantalla)

### **Timing**
- âš ï¸ No te apresures en las transiciones (deja 1-2 segundos entre acciones)
- âš ï¸ Si cometes un error, **pausa grabaciÃ³n y reinicia esa secciÃ³n** (edita despuÃ©s)
- âœ… Practica el script 2-3 veces antes de grabar final

### **EdiciÃ³n (Opcional)**
- **Necesario**: Cortar intro/outro si usas Loom
- **Opcional**: Agregar texto overlay con tu nombre y proyecto
- **Herramientas gratis**:
  - Mac: iMovie
  - Windows: Microsoft Clipchamp
  - Multiplataforma: CapCut (web)

---

## ðŸ“¤ PublicaciÃ³n del Video

### **OpciÃ³n 1: YouTube (Recomendado)**
```
1. Subir a YouTube (cuenta personal)
2. Configurar como "No listado" si no quieres que sea pÃºblico
3. TÃ­tulo: "MoodTune - AI Music Discovery | Bootcamp IA Project"
4. DescripciÃ³n corta: Ver abajo
5. Copiar link y poner en README
```

**DescripciÃ³n sugerida para YouTube**:
```
MoodTune - AI-Powered Music Discovery Assistant

Demo del proyecto final del Bootcamp de Inteligencia Artificial.

TecnologÃ­as:
- Frontend: Next.js 14 + TypeScript
- Backend: FastAPI + Python
- AI: OpenAI GPT-4o-mini (LLM)
- Music API: Deezer

Repository: [tu-github-link-aquÃ­]

Autor: Umit Gungor
Fecha: Febrero 2026
```

### **OpciÃ³n 2: Loom**
```
1. Grabar directamente con Loom (extensiÃ³n de Chrome)
2. Auto-sube a Loom cloud
3. Copiar link shareable
4. Poner en README
```

### **OpciÃ³n 3: Google Drive**
```
1. Subir archivo .mp4
2. Click derecho â†’ "Obtener enlace" â†’ "Cualquiera con el enlace"
3. Copiar link
4. Poner en README
```

---

## âœ… Update del README despuÃ©s de grabar

```markdown
## ðŸŽ¥ Demo

ðŸŽ¬ **Watch MoodTune in action**: [Video Demo (3 min)](https://youtube.com/...)

**What you'll see**:
- Natural language mood input (e.g., "sad and melancholic after a breakup")
- AI analyzing the emotional context in real-time
- Personalized music recommendations
- 30-second audio previews
- Bilingual support (Spanish â†” English)
- Dark/Light theme toggle
```

---

## ðŸš¨ Troubleshooting

### **Problema: Backend no responde**
```bash
# Verificar que estÃ¡ corriendo:
curl http://localhost:8000/api/health

# Si no responde, reiniciar:
cd backend
source venv/bin/activate  # Mac/Linux
python main.py
```

### **Problema: Frontend da error de CORS**
```bash
# Verificar NEXT_PUBLIC_API_URL en .env.local:
echo "NEXT_PUBLIC_API_URL=http://localhost:8000" > frontend/.env.local

# Reiniciar frontend:
cd frontend
npm run dev
```

### **Problema: OpenAI API key invÃ¡lida**
```bash
# Verificar .env en backend:
cd backend
cat .env  # Debe tener OPENAI_API_KEY=sk-proj-...

# Si falta, recrear:
echo "OPENAI_API_KEY=tu-key-aqui" > .env
```

### **Problema: Previews de audio no suenan**
- âœ… Verificar que tu navegador permite autoplay (Chrome puede bloquearlo)
- âœ… Verificar volumen del sistema
- âœ… Algunos tracks de Deezer no tienen preview â†’ probar con otra canciÃ³n

---

## ðŸ“Š Checklist Post-GrabaciÃ³n

- [ ] Video grabado (2-3 minutos)
- [ ] Audio claro y sin ruidos
- [ ] Se ven todas las features principales
- [ ] Video subido a YouTube/Loom/Drive
- [ ] Link agregado a README.md
- [ ] Link agregado a BRIEFING.md (si corresponde)
- [ ] Video testeado (reproducible por otros)

---

**Â¡Ã‰xito con la grabaciÃ³n! ðŸŽ¬ðŸŽµ**

Si tienes problemas, recuerda:
- No necesita ser perfecto, solo funcional y claro
- 2-3 minutos es suficiente (no te extiendas)
- Muestra el valor del proyecto, no cada lÃ­nea de cÃ³digo
